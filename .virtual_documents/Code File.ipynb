#dependencies
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt


train_data = pd.read_excel('Dataset.xlsx')


train_data.head()





train_data.shape


train_data.isna().sum() #to check missing values in my data frame


train_data.dropna(inplace=True) #inplace= True, to modify my dataframe as well


train_data.isna().sum()





train_data.dtypes





def change_into_datetime(col):
    train_data[col] =pd.to_datetime(train_data[col])


for i in ['Date_of_Journey','Dep_Time','Arrival_Time']:
    change_into_datetime(i)


train_data.dtypes





train_data['Travel_year'] = train_data['Date_of_Journey'].dt.year
train_data['Travel_month'] = train_data['Date_of_Journey'].dt.month
train_data['Travel_day'] = train_data['Date_of_Journey'].dt.day


train_data.head()


#dropping 'Date_of_Journey' column from by dataframe
train_data.drop('Date_of_Journey',axis=1,inplace=True)


train_data['Travel_year'].value_counts()


#so no need of 'Travel_year' colulmn as well
train_data.drop('Travel_year',axis=1,inplace=True)


train_data.head()





#creating function
def extract_hour(df,col):
    df[col+'_hour'] = df[col].dt.month

def extract_min(df,col):
    df[col+'_min'] = df[col].dt.minute

def drop_column(df,col):
    df.drop(col,axis=1,inplace=True)
    


#calling those functions for Dep_Time column
extract_hour(train_data,'Dep_Time')
extract_min(train_data,'Dep_Time')
drop_column(train_data,'Dep_Time')


train_data.head()


#calling those functions for Arrival_Time column
extract_hour(train_data,'Arrival_Time')
extract_min(train_data,'Arrival_Time')
drop_column(train_data,'Arrival_Time')


train_data.head()





'4h 45m'.split()


#to keep a single format of Duration column : xh ym
duration = list(train_data['Duration'])
for i in range (len(duration)):
    if len(duration[i].split())!=2:
        if 'h' in duration[i]:
            duration[i] = duration[i] + ' 0m'
        else:
            duration[i] = ' 0h' + duration[i]
        
            


train_data['Duration'] = duration


train_data.head()


'4h 45m'.split(' ')[1] #output will be 45m


'4h 45m'.split(' ')[1][0:-1] #output will be 45. & that's what we need


#to access the minute and hour of Duration 
def hour(x):
    return x.split(' ')[0][0:-1]

def mins(x):
    return x.split(' ')[1][0:-1]


train_data['Duration_Hour']=train_data['Duration'].apply(hour)
train_data['Duration_Minutes'] = train_data['Duration'].apply(mins)


train_data.head()


train_data.drop('Duration',axis=1,inplace=True)


train_data.head()


train_data.dtypes


#need to change Duration_Hour & Duration_Minutes's data type
train_data['Duration_Hour'] = train_data['Duration_Hour'].astype(int)
train_data['Duration_Minutes']=train_data['Duration_Minutes'].astype(int)


print(train_data['Duration_Hour'].unique())
print(train_data['Duration_Minutes'].unique())
#due to minute's '0h5' value, i couldn't convert the data to int


# remove the '0h' prefix and keep just the numeric part
train_data['Duration_Minutes'] = train_data['Duration_Minutes'].replace(r'0h', '', regex=True)


# Replace any remaining empty strings or non-numeric values with '0'
train_data['Duration_Hour'] = train_data['Duration_Hour'].replace(r'^\s*$', '0', regex=True)
train_data['Duration_Minutes'] = train_data['Duration_Minutes'].replace(r'^\s*$', '0', regex=True)

# Now try converting to int again
train_data['Duration_Hour'] = train_data['Duration_Hour'].astype(int)
train_data['Duration_Minutes'] = train_data['Duration_Minutes'].astype(int)



print(train_data['Duration_Hour'].unique())
print(train_data['Duration_Minutes'].unique())
#no more '0h5'


train_data.dtypes





cat_col= train_data.select_dtypes(include=['object'])
cat_col



cont_col = train_data.select_dtypes(include= ['int32', 'int64'] )
cont_col.head()



cat_col.columns


cat_col.tail()


# creating function to visualize the distribution of data for each category in a categorical variable
def cat_col_vs_price (col):
    plt.figure(figsize=(15,5))
    sns.boxplot(data=train_data.sort_values('Price',ascending=False),x=col,y='Price')


#creating function to apply one-hot encoder to nominal data
def dummy_df (col):
    return pd.get_dummies(data=cat_col[col]).astype(int)


cat_col.value_counts('Airline')


Airline_vs_price = cat_col_vs_price('Airline')


#applying one-hot encoder
Airline = dummy_df('Airline')
Airline.head()


cat_col.value_counts('Source')


Source_vs_Price = cat_col_vs_price('Source')


#appying one-hot encoder
Source = dummy_df('Source')
Source.head()


cat_col.value_counts('Destination')


Destination_vs_Price = cat_col_vs_price('Destination')


#appying one-hot encoder
Destination = dummy_df('Destination')
Destination.head()





cat_col['Route_1'] = cat_col['Route'].str.split('→').str[0]
cat_col['Route_2'] = cat_col['Route'].str.split('→').str[1]
cat_col['Route_3'] = cat_col['Route'].str.split('→').str[2]
cat_col['Route_4'] = cat_col['Route'].str.split('→').str[3]
cat_col['Route_5'] = cat_col['Route'].str.split('→').str[4]


cat_col.head()


drop_column(cat_col,'Route')


cat_col.head()


cat_col.isnull().sum()


for i in ['Route_3','Route_4','Route_5'] :
    cat_col[i].fillna('None',inplace= True)


cat_col.isnull().sum()


for i in cat_col.columns:
    print('{} has total {} catagories'.format(i,len(cat_col[i].unique())))





from sklearn.preprocessing import LabelEncoder


for i in ['Route_1','Route_2', 'Route_3', 'Route_4', 'Route_5'] :
    cat_col[i]= LabelEncoder().fit_transform(cat_col[i])





cat_col.head()


cat_col['Additional_Info'].value_counts()


drop_column(cat_col,'Additional_Info')


cat_col.head()





cat_col.value_counts('Total_Stops')


Total_Stops_vs_Price = cat_col_vs_price('Total_Stops')


#encoding by mapping dictionary
dict = {'non-stop':0,'1 stop':1,'2 stops':2,'3 stops':3,'4 stops':4}
cat_col['Total_Stops']= cat_col['Total_Stops'].map(dict)


cat_col.head()





train_data = pd.concat([Airline,Source,Destination,cat_col['Total_Stops'] ,cat_col['Route_1'] ,cat_col['Route_2'] ,cat_col['Route_3'] ,cat_col['Route_4'] ,cat_col['Route_5'] ,cont_col],axis=1)


train_data.head()


#to see all the 38 columns 
pd.set_option('display.max_columns',38)
train_data.head()





def plot(df,col):
    #fig,(ax1,ax2)=plt.subplots(2,1) #this sets up a figure with two subplots (stacked vertically).
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5)) #this sets up a figure with two subplots (stacked horizontally).
    sns.distplot(df[col],ax=ax1)
    sns.boxplot(df[col],ax=ax2)


plot(train_data,'Price')


train_data['Price']= np.where(train_data['Price']>40000,train_data['Price'].median(),train_data['Price'])


plot(train_data,'Price') #decreased the numbers of outlier 





X = train_data.drop('Price',axis=1)
X.head()


Y= train_data['Price']
Y


X.shape


Y.shape





from sklearn.feature_selection import mutual_info_classif


imp= pd.DataFrame(mutual_info_classif(X,Y),index=X.columns)
imp


#to know about the dependency of the attributes with the target variable
imp.columns = ['Importance']
imp.sort_values(by=['Importance'],ascending=False)


#we can drop 'Vistara Premium economy' 
drop_column(X,'Vistara Premium economy')


X.head()





from sklearn.model_selection import train_test_split


X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state=42)


from sklearn import metrics
def predict(ml_model):
    model = m1_model.fit(X_train,Y_train)
    print('Training Score: {}'.format(model.score(X_train,Y_Train)))
    prediction= model.predict(X_test)
    print('Predictions are {}'.format(prediction))
    print('\n')
    r2_score =  metrics.r2_score(Y_test,prediction)
    print('r2 score is {}'.format(r2_score))

    print('MAE :',metrics.mean_absolute_error(Y_test,prediction))
    print('MSE :',metrics.mean_squared_error(Y_test,prediction))
    print('RMSE :',np.sqrt(metrics.mean_absolute_error(Y_test,prediction)))

    sns.distplot(Y_test=prediction)





from sklearn.ensemble import RandomForestRegressor
predict(RandomForestRegressor())









